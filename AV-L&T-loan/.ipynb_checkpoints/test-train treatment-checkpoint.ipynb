{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/home/monster/Downloads/kaggle/AV-L&T-loan/train.csv')\n",
    "test_df = pd.read_csv('/home/monster/Downloads/kaggle/AV-L&T-loan/test.csv')\n",
    "sub_df = pd.read_csv('/home/monster/Downloads/kaggle/AV-L&T-loan/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((233154, 41), (112392, 40))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape,test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['is_train'] = ''\n",
    "test_df['is_train'] = ''\n",
    "data = pd.DataFrame()\n",
    "train_df.loc[:,'is_train'] = 1\n",
    "test_df.loc[:,'is_train'] = 0\n",
    "data = data.append(train_df,sort=False).append(test_df,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treat missing values\n",
    "#86 % values are no so it is safe to impute NO\n",
    "train_df['Employment.Type'].fillna('Self employed',inplace=True)\n",
    "test_df['Employment.Type'].fillna('Self employed',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UniqueID                               0\n",
       "disbursed_amount                       0\n",
       "asset_cost                             0\n",
       "ltv                                    0\n",
       "branch_id                              0\n",
       "supplier_id                            0\n",
       "manufacturer_id                        0\n",
       "Current_pincode_ID                     0\n",
       "Date.of.Birth                          0\n",
       "Employment.Type                        0\n",
       "DisbursalDate                          0\n",
       "State_ID                               0\n",
       "Employee_code_ID                       0\n",
       "MobileNo_Avl_Flag                      0\n",
       "Aadhar_flag                            0\n",
       "PAN_flag                               0\n",
       "VoterID_flag                           0\n",
       "Driving_flag                           0\n",
       "Passport_flag                          0\n",
       "PERFORM_CNS.SCORE                      0\n",
       "PERFORM_CNS.SCORE.DESCRIPTION          0\n",
       "PRI.NO.OF.ACCTS                        0\n",
       "PRI.ACTIVE.ACCTS                       0\n",
       "PRI.OVERDUE.ACCTS                      0\n",
       "PRI.CURRENT.BALANCE                    0\n",
       "PRI.SANCTIONED.AMOUNT                  0\n",
       "PRI.DISBURSED.AMOUNT                   0\n",
       "SEC.NO.OF.ACCTS                        0\n",
       "SEC.ACTIVE.ACCTS                       0\n",
       "SEC.OVERDUE.ACCTS                      0\n",
       "SEC.CURRENT.BALANCE                    0\n",
       "SEC.SANCTIONED.AMOUNT                  0\n",
       "SEC.DISBURSED.AMOUNT                   0\n",
       "PRIMARY.INSTAL.AMT                     0\n",
       "SEC.INSTAL.AMT                         0\n",
       "NEW.ACCTS.IN.LAST.SIX.MONTHS           0\n",
       "DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS    0\n",
       "AVERAGE.ACCT.AGE                       0\n",
       "CREDIT.HISTORY.LENGTH                  0\n",
       "NO.OF_INQUIRIES                        0\n",
       "loan_default                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.apply(lambda x: sum(x.isnull()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112392, 40), (233154, 41), (112392, 40))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape,train_df.shape,test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create mean and st dev features- leakage features\n",
    "ft_name = ['loan_default']\n",
    "var = ['branch_id','State_ID']\n",
    "fntouse = list([np.mean,np.sum])\n",
    "\n",
    "# temp2 = data.pivot_table(values='ltv',index=['Current_pincode_ID'],aggfunc=np.std)\n",
    "# # temp2.plot(kind='bar')\n",
    "# temp2.reset_index(inplace=True)\n",
    "# temp2.columns = ['Current_pincode_ID', 'ltv_stdev']\n",
    "for ftname in ft_name:\n",
    "    for fn2use in fntouse:\n",
    "        for var_name in var:\n",
    "            temp3 = train_df.pivot_table(values=ftname,index=[var_name],aggfunc=fn2use)\n",
    "            # temp2.plot(kind='bar')\n",
    "            temp3.reset_index(inplace=True)\n",
    "            temp3.columns = [var_name, var_name+'_'+ftname+'_'+str(fn2use).split(' ')[1]]\n",
    "            train_df = train_df.merge(temp3,on=var_name, how = 'left')\n",
    "            test_df = test_df.merge(temp3,on=var_name, how = 'left')\n",
    "    #         data[var_name+'_stdev'] = data[ftname]-data[var_name+'_'+ftname+'_mean']\n",
    "\n",
    "            # df = pd.concat([temp2,temp3],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['CREDIT.HISTORY.LENGTH.YEARS'] = train_df['CREDIT.HISTORY.LENGTH'].map(lambda x : int(x.split(' ')[0][:-3]))\n",
    "\n",
    "test_df['CREDIT.HISTORY.LENGTH.YEARS'] = test_df['CREDIT.HISTORY.LENGTH'].map(lambda x : int(x.split(' ')[0][:-3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['CREDIT.HISTORY.LENGTH.MONTHS'] = train_df['CREDIT.HISTORY.LENGTH'].map(lambda x : int(x.split(' ')[1][:-3]))\n",
    "\n",
    "test_df['CREDIT.HISTORY.LENGTH.MONTHS'] = test_df['CREDIT.HISTORY.LENGTH'].map(lambda x : int(x.split(' ')[1][:-3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['CREDIT.HISTORY.LENGTH.TOTMONS'] = train_df['CREDIT.HISTORY.LENGTH.MONTHS'] + np.dot(train_df['CREDIT.HISTORY.LENGTH.YEARS'],12)\n",
    "\n",
    "test_df['CREDIT.HISTORY.LENGTH.TOTMONS'] = test_df['CREDIT.HISTORY.LENGTH.MONTHS'] + np.dot(test_df['CREDIT.HISTORY.LENGTH.YEARS'],12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['AVERAGE.ACCT.AGE.YEARS'] = train_df['AVERAGE.ACCT.AGE'].map(lambda x : int(x.split(' ')[0][:-3]))\n",
    "\n",
    "train_df['AVERAGE.ACCT.AGE.MONTHS'] = train_df['AVERAGE.ACCT.AGE'].map(lambda x : int(x.split(' ')[1][:-3]))\n",
    "\n",
    "train_df['AVERAGE.ACCT.AGE.TOTMONS'] = train_df['AVERAGE.ACCT.AGE.MONTHS'] + np.dot(train_df['AVERAGE.ACCT.AGE.YEARS'],12)\n",
    "\n",
    "\n",
    "\n",
    "test_df['AVERAGE.ACCT.AGE.YEARS'] = test_df['AVERAGE.ACCT.AGE'].map(lambda x : int(x.split(' ')[0][:-3]))\n",
    "\n",
    "test_df['AVERAGE.ACCT.AGE.MONTHS'] = test_df['AVERAGE.ACCT.AGE'].map(lambda x : int(x.split(' ')[1][:-3]))\n",
    "\n",
    "test_df['AVERAGE.ACCT.AGE.TOTMONS'] = test_df['AVERAGE.ACCT.AGE.MONTHS'] + np.dot(test_df['AVERAGE.ACCT.AGE.YEARS'],12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date.of.Birth'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Date.of.Birth.YEAR'] = train_df['Date.of.Birth'].map(lambda x : int(x.split('-')[2]))\n",
    "\n",
    "test_df['Date.of.Birth.YEAR'] = test_df['Date.of.Birth'].map(lambda x : int(x.split('-')[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Date.of.Birth.YEAR.conv'] = ''\n",
    "\n",
    "test_df['Date.of.Birth.YEAR.conv'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df['Date.of.Birth.YEAR']==0,'Date.of.Birth.YEAR.conv'] = 2000\n",
    "\n",
    "test_df.loc[test_df['Date.of.Birth.YEAR']==0,'Date.of.Birth.YEAR.conv'] = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df['Date.of.Birth.YEAR']>0,'Date.of.Birth.YEAR.conv'] = train_df.loc[train_df['Date.of.Birth.YEAR']>0,'Date.of.Birth.YEAR']+1900\n",
    "\n",
    "test_df.loc[test_df['Date.of.Birth.YEAR']>0,'Date.of.Birth.YEAR.conv'] = test_df.loc[test_df['Date.of.Birth.YEAR']>0,'Date.of.Birth.YEAR']+1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Date.of.Birth.AGE'] = ''\n",
    "\n",
    "train_df['Date.of.Birth.AGE'] = 2019 - train_df.loc[:,'Date.of.Birth.YEAR.conv']\n",
    "\n",
    "test_df['Date.of.Birth.AGE'] = ''\n",
    "\n",
    "test_df['Date.of.Birth.AGE'] = 2019 - test_df.loc[:,'Date.of.Birth.YEAR.conv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#st dev and mean of ltv feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = data.pivot_table(values='loan_default',index=['branch_id'],aggfunc=np.mean)\n",
    "# print('Frequency Table for Credit History:') \n",
    "# print(temp2)\n",
    "\n",
    "# fig = plt.figure(figsize=(8,4))\n",
    "# ax1 = fig.add_subplot(121)\n",
    "# ax1.set_xlabel('Credit_History')\n",
    "# ax1.set_ylabel('Count of Applicants')\n",
    "# ax1.set_title(\"Applicants by Credit_History\")\n",
    "temp2.plot(kind='bar')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create mean and st dev features\n",
    "\n",
    "\n",
    "ft_name = ['disbursed_amount','asset_cost','ltv','PERFORM_CNS.SCORE','PRIMARY.INSTAL.AMT']\n",
    "\n",
    "\n",
    "#All 208 features - aggregated\n",
    "\n",
    "# ft_name = ['disbursed_amount','asset_cost','ltv','PERFORM_CNS.SCORE','PRIMARY.INSTAL.AMT',\n",
    "#            'PRI.NO.OF.ACCTS', 'PRI.ACTIVE.ACCTS',\n",
    "#        'PRI.OVERDUE.ACCTS', 'PRI.CURRENT.BALANCE', 'PRI.SANCTIONED.AMOUNT',\n",
    "#        'PRI.DISBURSED.AMOUNT', 'SEC.NO.OF.ACCTS', 'SEC.ACTIVE.ACCTS',\n",
    "#        'SEC.OVERDUE.ACCTS', 'SEC.CURRENT.BALANCE', 'SEC.SANCTIONED.AMOUNT',\n",
    "#        'SEC.DISBURSED.AMOUNT', 'SEC.INSTAL.AMT',\n",
    "#        'NEW.ACCTS.IN.LAST.SIX.MONTHS', 'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS',]\n",
    "\n",
    "\n",
    "    \n",
    "var = ['Current_pincode_ID','branch_id','supplier_id','manufacturer_id','State_ID','Employee_code_ID']\n",
    "# temp2 = data.pivot_table(values='ltv',index=['Current_pincode_ID'],aggfunc=np.std)\n",
    "# # temp2.plot(kind='bar')\n",
    "# temp2.reset_index(inplace=True)\n",
    "# temp2.columns = ['Current_pincode_ID', 'ltv_stdev']\n",
    "for ftname in ft_name:\n",
    "    for var_name in var:\n",
    "        temp3 = train_df.pivot_table(values=ftname,index=[var_name],aggfunc=np.mean)\n",
    "        \n",
    "        temp4 = test_df.pivot_table(values=ftname,index=[var_name],aggfunc=np.mean)\n",
    "\n",
    "        # temp2.plot(kind='bar')\n",
    "        temp3.reset_index(inplace=True)\n",
    "        temp4.reset_index(inplace=True)\n",
    "        \n",
    "        temp3.columns = [var_name, var_name+'_'+ftname+'_mean']\n",
    "        temp4.columns = [var_name, var_name+'_'+ftname+'_mean']\n",
    "        \n",
    "        train_df = train_df.merge(temp3,on=var_name, how = 'left')\n",
    "        test_df = test_df.merge(temp4,on=var_name, how = 'left')\n",
    "        \n",
    "        train_df[var_name+'_stdev'] = train_df[ftname]-train_df[var_name+'_'+ftname+'_mean']\n",
    "        \n",
    "        test_df[var_name+'_stdev'] = test_df[ftname]-test_df[var_name+'_'+ftname+'_mean']\n",
    "\n",
    "        # df = pd.concat([temp2,temp3],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.merge(temp3,on='Current_pincode_ID', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['ltv_stdev'] = data['ltv']-data['ltv_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['PERFORM_CNS.SCORE.DESCRIPTION'] = train_df['PERFORM_CNS.SCORE.DESCRIPTION'].replace(' ', '_', regex=True)\n",
    "\n",
    "test_df['PERFORM_CNS.SCORE.DESCRIPTION'] = test_df['PERFORM_CNS.SCORE.DESCRIPTION'].replace(' ', '_', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treat categorical variables\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "d = pd.DataFrame()\n",
    "\n",
    "var_mod = ['Employment.Type','PERFORM_CNS.SCORE.DESCRIPTION']\n",
    "\n",
    "x = pd.get_dummies(train_df[var_mod])\n",
    "x1 = pd.get_dummies(test_df[var_mod])\n",
    "\n",
    "train_df  = train_df.drop(var_mod,axis=1)\n",
    "train_df = pd.concat([train_df,x], axis=1)\n",
    "\n",
    "test_df  = test_df.drop(var_mod,axis=1)\n",
    "test_df = pd.concat([test_df,x1], axis=1)\n",
    "\n",
    "\n",
    "# for i in var_mod:\n",
    "#     print(i)\n",
    "# #     d[str(i)] \n",
    "#     dd = le.fit_transform(data.loc[:,i]).toarray()\n",
    "#     print(dd.shape)\n",
    "# d.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((233154, 110), (112392, 108))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape,test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_list = np.setdiff1d(list(train_df.columns),list(test_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PERFORM_CNS.SCORE.DESCRIPTION_Not_Scored:_More_than_50_active_Accounts_found',\n",
       "       'loan_default'], dtype='<U85')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_list #need to drop these variables from both test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ltv'].hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data['ltv']**2).hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data['ltv']**1/3).hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['log_disbursed_amount'] = np.log(data['disbursed_amount'])\n",
    "data['log_asset_cost'] = np.log(data['asset_cost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ltv_squared'] = data['ltv']**2\n",
    "data['log_ltv'] = np.log(data['ltv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DisbursalDate_month'] = data['DisbursalDate'].map(lambda x : int(x.split('-')[1]))\n",
    "data['DisbursalDate_dayofmonth'] = data['DisbursalDate'].map(lambda x : int(x.split('-')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data['AVERAGE.ACCT.AGE'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data['CREDIT.HISTORY.LENGTH'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data.loc[data['is_train']==1,:]\n",
    "train_df = train_df.drop(['is_train'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = data.loc[data['is_train']==0,:]\n",
    "test_df = test_df.drop(['is_train','loan_default'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.apply(lambda x: sum(x.isnull()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.apply(lambda x: sum(x.isnull()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape,test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictors = [\n",
    "#  'disbursed_amount',\n",
    "#  'asset_cost',\n",
    "#  'ltv',\n",
    "#  'branch_id',\n",
    "#  'supplier_id',\n",
    "#  'manufacturer_id',\n",
    "#  'Current_pincode_ID',\n",
    "#  'State_ID',\n",
    "#  'Employee_code_ID',\n",
    "#  'MobileNo_Avl_Flag',\n",
    "#  'Aadhar_flag',\n",
    "#  'PAN_flag',\n",
    "#  'VoterID_flag',\n",
    "#  'Driving_flag',\n",
    "#  'Passport_flag',\n",
    "#  'PERFORM_CNS.SCORE',\n",
    "#  'PRI.NO.OF.ACCTS',\n",
    "#  'PRI.ACTIVE.ACCTS',\n",
    "#  'PRI.OVERDUE.ACCTS',\n",
    "#  'PRI.CURRENT.BALANCE',\n",
    "#  'PRI.SANCTIONED.AMOUNT',\n",
    "#  'PRI.DISBURSED.AMOUNT',\n",
    "#  'SEC.NO.OF.ACCTS',\n",
    "#  'SEC.ACTIVE.ACCTS',\n",
    "#  'SEC.OVERDUE.ACCTS',\n",
    "#  'SEC.CURRENT.BALANCE',\n",
    "#  'SEC.SANCTIONED.AMOUNT',\n",
    "#  'SEC.DISBURSED.AMOUNT',\n",
    "#  'PRIMARY.INSTAL.AMT',\n",
    "#  'SEC.INSTAL.AMT',\n",
    "#  'NEW.ACCTS.IN.LAST.SIX.MONTHS',\n",
    "#  'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS',\n",
    "#  'NO.OF_INQUIRIES',\n",
    "#  'branch_id_loan_default_mean',\n",
    "#  'State_ID_loan_default_mean',\n",
    "#  'branch_id_loan_default_sum',\n",
    "#  'State_ID_loan_default_sum',\n",
    "#  'CREDIT.HISTORY.LENGTH.YEARS',\n",
    "#  'CREDIT.HISTORY.LENGTH.MONTHS',\n",
    "#  'CREDIT.HISTORY.LENGTH.TOTMONS',\n",
    "#  'AVERAGE.ACCT.AGE.YEARS',\n",
    "#  'AVERAGE.ACCT.AGE.MONTHS',\n",
    "#  'AVERAGE.ACCT.AGE.TOTMONS',\n",
    "#  'Date.of.Birth.YEAR',\n",
    "#  'Date.of.Birth.YEAR.conv',\n",
    "#  'Date.of.Birth.AGE',\n",
    "#  'Current_pincode_ID_disbursed_amount_mean',\n",
    "#  'Current_pincode_ID_stdev',\n",
    "#  'branch_id_disbursed_amount_mean',\n",
    "#  'branch_id_stdev',\n",
    "#  'supplier_id_disbursed_amount_mean',\n",
    "#  'supplier_id_stdev',\n",
    "#  'manufacturer_id_disbursed_amount_mean',\n",
    "#  'manufacturer_id_stdev',\n",
    "#  'State_ID_disbursed_amount_mean',\n",
    "#  'State_ID_stdev',\n",
    "#  'Employee_code_ID_disbursed_amount_mean',\n",
    "#  'Employee_code_ID_stdev',\n",
    "#  'Current_pincode_ID_asset_cost_mean',\n",
    "#  'branch_id_asset_cost_mean',\n",
    "#  'supplier_id_asset_cost_mean',\n",
    "#  'manufacturer_id_asset_cost_mean',\n",
    "#  'State_ID_asset_cost_mean',\n",
    "#  'Employee_code_ID_asset_cost_mean',\n",
    "#  'Current_pincode_ID_ltv_mean',\n",
    "#  'branch_id_ltv_mean',\n",
    "#  'supplier_id_ltv_mean',\n",
    "#  'manufacturer_id_ltv_mean',\n",
    "#  'State_ID_ltv_mean',\n",
    "#  'Employee_code_ID_ltv_mean',\n",
    "#  'Current_pincode_ID_PERFORM_CNS.SCORE_mean',\n",
    "#  'branch_id_PERFORM_CNS.SCORE_mean',\n",
    "#  'supplier_id_PERFORM_CNS.SCORE_mean',\n",
    "#  'manufacturer_id_PERFORM_CNS.SCORE_mean',\n",
    "#  'State_ID_PERFORM_CNS.SCORE_mean',\n",
    "#  'Employee_code_ID_PERFORM_CNS.SCORE_mean',\n",
    "#  'Current_pincode_ID_PRIMARY.INSTAL.AMT_mean',\n",
    "#  'branch_id_PRIMARY.INSTAL.AMT_mean',\n",
    "#  'supplier_id_PRIMARY.INSTAL.AMT_mean',\n",
    "#  'manufacturer_id_PRIMARY.INSTAL.AMT_mean',\n",
    "#  'State_ID_PRIMARY.INSTAL.AMT_mean',\n",
    "#  'Employee_code_ID_PRIMARY.INSTAL.AMT_mean',\n",
    "#  'Current_pincode_ID_PRI.NO.OF.ACCTS_mean',\n",
    "#  'branch_id_PRI.NO.OF.ACCTS_mean',\n",
    "#  'supplier_id_PRI.NO.OF.ACCTS_mean',\n",
    "#  'manufacturer_id_PRI.NO.OF.ACCTS_mean',\n",
    "#  'State_ID_PRI.NO.OF.ACCTS_mean',\n",
    "#  'Employee_code_ID_PRI.NO.OF.ACCTS_mean',\n",
    "#  'Current_pincode_ID_PRI.ACTIVE.ACCTS_mean',\n",
    "#  'branch_id_PRI.ACTIVE.ACCTS_mean',\n",
    "#  'supplier_id_PRI.ACTIVE.ACCTS_mean',\n",
    "#  'manufacturer_id_PRI.ACTIVE.ACCTS_mean',\n",
    "#  'State_ID_PRI.ACTIVE.ACCTS_mean',\n",
    "#  'Employee_code_ID_PRI.ACTIVE.ACCTS_mean',\n",
    "#  'Current_pincode_ID_PRI.OVERDUE.ACCTS_mean',\n",
    "#  'branch_id_PRI.OVERDUE.ACCTS_mean',\n",
    "#  'supplier_id_PRI.OVERDUE.ACCTS_mean',\n",
    "#  'manufacturer_id_PRI.OVERDUE.ACCTS_mean',\n",
    "#  'State_ID_PRI.OVERDUE.ACCTS_mean',\n",
    "#  'Employee_code_ID_PRI.OVERDUE.ACCTS_mean',\n",
    "#  'Current_pincode_ID_PRI.CURRENT.BALANCE_mean',\n",
    "#  'branch_id_PRI.CURRENT.BALANCE_mean',\n",
    "#  'supplier_id_PRI.CURRENT.BALANCE_mean',\n",
    "#  'manufacturer_id_PRI.CURRENT.BALANCE_mean',\n",
    "#  'State_ID_PRI.CURRENT.BALANCE_mean',\n",
    "#  'Employee_code_ID_PRI.CURRENT.BALANCE_mean',\n",
    "#  'Current_pincode_ID_PRI.SANCTIONED.AMOUNT_mean',\n",
    "#  'branch_id_PRI.SANCTIONED.AMOUNT_mean',\n",
    "#  'supplier_id_PRI.SANCTIONED.AMOUNT_mean',\n",
    "#  'manufacturer_id_PRI.SANCTIONED.AMOUNT_mean',\n",
    "#  'State_ID_PRI.SANCTIONED.AMOUNT_mean',\n",
    "#  'Employee_code_ID_PRI.SANCTIONED.AMOUNT_mean',\n",
    "#  'Current_pincode_ID_PRI.DISBURSED.AMOUNT_mean',\n",
    "#  'branch_id_PRI.DISBURSED.AMOUNT_mean',\n",
    "#  'supplier_id_PRI.DISBURSED.AMOUNT_mean',\n",
    "#  'manufacturer_id_PRI.DISBURSED.AMOUNT_mean',\n",
    "#  'State_ID_PRI.DISBURSED.AMOUNT_mean',\n",
    "#  'Employee_code_ID_PRI.DISBURSED.AMOUNT_mean',\n",
    "#  'Current_pincode_ID_SEC.NO.OF.ACCTS_mean',\n",
    "#  'branch_id_SEC.NO.OF.ACCTS_mean',\n",
    "#  'supplier_id_SEC.NO.OF.ACCTS_mean',\n",
    "#  'manufacturer_id_SEC.NO.OF.ACCTS_mean',\n",
    "#  'State_ID_SEC.NO.OF.ACCTS_mean',\n",
    "#  'Employee_code_ID_SEC.NO.OF.ACCTS_mean',\n",
    "#  'Current_pincode_ID_SEC.ACTIVE.ACCTS_mean',\n",
    "#  'branch_id_SEC.ACTIVE.ACCTS_mean',\n",
    "#  'supplier_id_SEC.ACTIVE.ACCTS_mean',\n",
    "#  'manufacturer_id_SEC.ACTIVE.ACCTS_mean',\n",
    "#  'State_ID_SEC.ACTIVE.ACCTS_mean',\n",
    "#  'Employee_code_ID_SEC.ACTIVE.ACCTS_mean',\n",
    "#  'Current_pincode_ID_SEC.OVERDUE.ACCTS_mean',\n",
    "#  'branch_id_SEC.OVERDUE.ACCTS_mean',\n",
    "#  'supplier_id_SEC.OVERDUE.ACCTS_mean',\n",
    "#  'manufacturer_id_SEC.OVERDUE.ACCTS_mean',\n",
    "#  'State_ID_SEC.OVERDUE.ACCTS_mean',\n",
    "#  'Employee_code_ID_SEC.OVERDUE.ACCTS_mean',\n",
    "#  'Current_pincode_ID_SEC.CURRENT.BALANCE_mean',\n",
    "#  'branch_id_SEC.CURRENT.BALANCE_mean',\n",
    "#  'supplier_id_SEC.CURRENT.BALANCE_mean',\n",
    "#  'manufacturer_id_SEC.CURRENT.BALANCE_mean',\n",
    "#  'State_ID_SEC.CURRENT.BALANCE_mean',\n",
    "#  'Employee_code_ID_SEC.CURRENT.BALANCE_mean',\n",
    "#  'Current_pincode_ID_SEC.SANCTIONED.AMOUNT_mean',\n",
    "#  'branch_id_SEC.SANCTIONED.AMOUNT_mean',\n",
    "#  'supplier_id_SEC.SANCTIONED.AMOUNT_mean',\n",
    "#  'manufacturer_id_SEC.SANCTIONED.AMOUNT_mean',\n",
    "#  'State_ID_SEC.SANCTIONED.AMOUNT_mean',\n",
    "#  'Employee_code_ID_SEC.SANCTIONED.AMOUNT_mean',\n",
    "#  'Current_pincode_ID_SEC.DISBURSED.AMOUNT_mean',\n",
    "#  'branch_id_SEC.DISBURSED.AMOUNT_mean',\n",
    "#  'supplier_id_SEC.DISBURSED.AMOUNT_mean',\n",
    "#  'manufacturer_id_SEC.DISBURSED.AMOUNT_mean',\n",
    "#  'State_ID_SEC.DISBURSED.AMOUNT_mean',\n",
    "#  'Employee_code_ID_SEC.DISBURSED.AMOUNT_mean',\n",
    "#  'Current_pincode_ID_SEC.INSTAL.AMT_mean',\n",
    "#  'branch_id_SEC.INSTAL.AMT_mean',\n",
    "#  'supplier_id_SEC.INSTAL.AMT_mean',\n",
    "#  'manufacturer_id_SEC.INSTAL.AMT_mean',\n",
    "#  'State_ID_SEC.INSTAL.AMT_mean',\n",
    "#  'Employee_code_ID_SEC.INSTAL.AMT_mean',\n",
    "#  'Current_pincode_ID_NEW.ACCTS.IN.LAST.SIX.MONTHS_mean',\n",
    "#  'branch_id_NEW.ACCTS.IN.LAST.SIX.MONTHS_mean',\n",
    "#  'supplier_id_NEW.ACCTS.IN.LAST.SIX.MONTHS_mean',\n",
    "#  'manufacturer_id_NEW.ACCTS.IN.LAST.SIX.MONTHS_mean',\n",
    "#  'State_ID_NEW.ACCTS.IN.LAST.SIX.MONTHS_mean',\n",
    "#  'Employee_code_ID_NEW.ACCTS.IN.LAST.SIX.MONTHS_mean',\n",
    "#  'Current_pincode_ID_DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS_mean',\n",
    "#  'branch_id_DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS_mean',\n",
    "#  'supplier_id_DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS_mean',\n",
    "#  'manufacturer_id_DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS_mean',\n",
    "#  'State_ID_DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS_mean',\n",
    "#  'Employee_code_ID_DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS_mean',\n",
    "#  'Employment.Type_Salaried',\n",
    "#  'Employment.Type_Self employed',\n",
    "#  'PERFORM_CNS.SCORE.DESCRIPTION_A-Very_Low_Risk',\n",
    "#  'PERFORM_CNS.SCORE.DESCRIPTION_B-Very_Low_Risk',\n",
    "#  'PERFORM_CNS.SCORE.DESCRIPTION_C-Very_Low_Risk',\n",
    "#  'PERFORM_CNS.SCORE.DESCRIPTION_D-Very_Low_Risk',\n",
    "#  'PERFORM_CNS.SCORE.DESCRIPTION_E-Low_Risk',\n",
    "#  'PERFORM_CNS.SCORE.DESCRIPTION_F-Low_Risk',\n",
    "#  'PERFORM_CNS.SCORE.DESCRIPTION_G-Low_Risk',\n",
    "#  'PERFORM_CNS.SCORE.DESCRIPTION_H-Medium_Risk',\n",
    "#  'PERFORM_CNS.SCORE.DESCRIPTION_I-Medium_Risk',\n",
    "#  'PERFORM_CNS.SCORE.DESCRIPTION_J-High_Risk',\n",
    "#  'PERFORM_CNS.SCORE.DESCRIPTION_K-High_Risk',\n",
    "#  'PERFORM_CNS.SCORE.DESCRIPTION_L-Very_High_Risk',\n",
    "#  'PERFORM_CNS.SCORE.DESCRIPTION_M-Very_High_Risk',\n",
    "#  'PERFORM_CNS.SCORE.DESCRIPTION_No_Bureau_History_Available',\n",
    "#  'PERFORM_CNS.SCORE.DESCRIPTION_Not_Scored:_More_than_50_active_Accounts_found',\n",
    "#  'PERFORM_CNS.SCORE.DESCRIPTION_Not_Scored:_No_Activity_seen_on_the_customer_(Inactive)',\n",
    "#  'PERFORM_CNS.SCORE.DESCRIPTION_Not_Scored:_No_Updates_available_in_last_36_months',\n",
    "#  'PERFORM_CNS.SCORE.DESCRIPTION_Not_Scored:_Not_Enough_Info_available_on_the_customer',\n",
    "#  'PERFORM_CNS.SCORE.DESCRIPTION_Not_Scored:_Only_a_Guarantor',\n",
    "#  'PERFORM_CNS.SCORE.DESCRIPTION_Not_Scored:_Sufficient_History_Not_Available',\n",
    "#  'log_disbursed_amount',\n",
    "#  'log_asset_cost',\n",
    "#  'ltv_squared',\n",
    "#  'DisbursalDate_month',\n",
    "#  'DisbursalDate_dayofmonth'\n",
    "#              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##Single best model predictors\n",
    "\n",
    "\n",
    "\n",
    "predictors = ['disbursed_amount', 'asset_cost', 'ltv',\n",
    "       'branch_id', 'supplier_id', 'manufacturer_id', 'Current_pincode_ID',\n",
    "       'State_ID', 'Employee_code_ID',\n",
    "       'MobileNo_Avl_Flag', 'Aadhar_flag', 'PAN_flag', 'VoterID_flag',\n",
    "       'Driving_flag', 'Passport_flag', 'PERFORM_CNS.SCORE', 'PRI.NO.OF.ACCTS',\n",
    "       'PRI.ACTIVE.ACCTS', 'PRI.OVERDUE.ACCTS', 'PRI.CURRENT.BALANCE',\n",
    "       'PRI.SANCTIONED.AMOUNT', 'PRI.DISBURSED.AMOUNT', 'SEC.NO.OF.ACCTS',\n",
    "       'SEC.ACTIVE.ACCTS', 'SEC.OVERDUE.ACCTS', 'SEC.CURRENT.BALANCE',\n",
    "       'SEC.SANCTIONED.AMOUNT', 'SEC.DISBURSED.AMOUNT', 'PRIMARY.INSTAL.AMT',\n",
    "       'SEC.INSTAL.AMT', 'NEW.ACCTS.IN.LAST.SIX.MONTHS',\n",
    "       'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS', 'NO.OF_INQUIRIES',\n",
    "       'CREDIT.HISTORY.LENGTH.YEARS', 'CREDIT.HISTORY.LENGTH.MONTHS',\n",
    "       'CREDIT.HISTORY.LENGTH.TOTMONS', 'AVERAGE.ACCT.AGE.YEARS',\n",
    "       'AVERAGE.ACCT.AGE.MONTHS', 'AVERAGE.ACCT.AGE.TOTMONS',\n",
    "       'Date.of.Birth.YEAR', 'Date.of.Birth.YEAR.conv', 'Date.of.Birth.AGE',\n",
    "       'Employment.Type_Salaried', 'Employment.Type_Self employed',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_A-Very_Low_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_B-Very_Low_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_C-Very_Low_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_D-Very_Low_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_E-Low_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_F-Low_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_G-Low_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_H-Medium_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_I-Medium_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_J-High_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_K-High_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_L-Very_High_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_M-Very_High_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_No_Bureau_History_Available',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_Not_Scored:_More_than_50_active_Accounts_found',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_Not_Scored:_No_Activity_seen_on_the_customer_(Inactive)',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_Not_Scored:_No_Updates_available_in_last_36_months',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_Not_Scored:_Not_Enough_Info_available_on_the_customer',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_Not_Scored:_Only_a_Guarantor',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_Not_Scored:_Sufficient_History_Not_Available',\n",
    "       'log_disbursed_amount', 'log_asset_cost', 'DisbursalDate_month',\n",
    "       'DisbursalDate_dayofmonth','Current_pincode_ID_disbursed_amount_mean',\n",
    " 'Current_pincode_ID_stdev',\n",
    " 'branch_id_disbursed_amount_mean',\n",
    " 'branch_id_stdev',\n",
    " 'supplier_id_disbursed_amount_mean',\n",
    " 'supplier_id_stdev',\n",
    " 'manufacturer_id_disbursed_amount_mean',\n",
    " 'manufacturer_id_stdev',\n",
    " 'State_ID_disbursed_amount_mean',\n",
    " 'State_ID_stdev',\n",
    " 'Employee_code_ID_disbursed_amount_mean',\n",
    " 'Employee_code_ID_stdev',\n",
    " 'Current_pincode_ID_asset_cost_mean',\n",
    " 'branch_id_asset_cost_mean',\n",
    " 'supplier_id_asset_cost_mean',\n",
    " 'manufacturer_id_asset_cost_mean',\n",
    " 'State_ID_asset_cost_mean',\n",
    " 'Employee_code_ID_asset_cost_mean',\n",
    " 'Current_pincode_ID_ltv_mean',\n",
    " 'branch_id_ltv_mean',\n",
    " 'supplier_id_ltv_mean',\n",
    " 'manufacturer_id_ltv_mean',\n",
    " 'State_ID_ltv_mean',\n",
    " 'Employee_code_ID_ltv_mean',\n",
    " 'Current_pincode_ID_PERFORM_CNS.SCORE_mean',\n",
    " 'branch_id_PERFORM_CNS.SCORE_mean',\n",
    " 'supplier_id_PERFORM_CNS.SCORE_mean',\n",
    " 'manufacturer_id_PERFORM_CNS.SCORE_mean',\n",
    " 'State_ID_PERFORM_CNS.SCORE_mean',\n",
    " 'Employee_code_ID_PERFORM_CNS.SCORE_mean',\n",
    " 'Current_pincode_ID_PRIMARY.INSTAL.AMT_mean',\n",
    " 'branch_id_PRIMARY.INSTAL.AMT_mean',\n",
    " 'supplier_id_PRIMARY.INSTAL.AMT_mean',\n",
    " 'manufacturer_id_PRIMARY.INSTAL.AMT_mean',\n",
    " 'State_ID_PRIMARY.INSTAL.AMT_mean',\n",
    " 'Employee_code_ID_PRIMARY.INSTAL.AMT_mean','branch_id_loan_default_mean',\n",
    "       'State_ID_loan_default_mean', 'branch_id_loan_default_sum',\n",
    "       'State_ID_loan_default_sum','ltv_squared','log_ltv']\n",
    "\n",
    "\n",
    "outcome = ['loan_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(train_df[predictors], train_df[outcome], test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,X_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import GridSearchCV   #Perforing grid search\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alg = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kf = loo.split(X_train_std[predictor_var])\n",
    "kf = KFold(n_splits=10).split(X_train[['State_ID','branch_id']])\n",
    "# ['branch_id', 'supplier_id', 'manufacturer_id', 'Current_pincode_ID','State_ID', 'Employee_code_ID']\n",
    "error = []\n",
    "# yavg = pd.DataFrame()\n",
    "\n",
    "for train, test in kf:\n",
    "    # Filter training data\n",
    "    print(\"training stared\")\n",
    "    train_predictors = X_train[predictors].iloc[train,:]\n",
    "\n",
    "    # The target we're using to train the algorithm.\n",
    "    train_target = y_train.iloc[train].values\n",
    "\n",
    "    # Training the algorithm using the predictors and target.\n",
    "    alg.fit(train_predictors, train_target)\n",
    "    y1 = alg.predict(X_train[predictors].iloc[test,:])\n",
    "#     yavg = yavg.append(pd.Series(y1),ignore_index=True)\n",
    "\n",
    "    #Record error from each cross-validation run\n",
    "    error.append(metrics.roc_auc_score(y_train.iloc[test], y1))\n",
    "    print('score for current fold',metrics.roc_auc_score(y_train.iloc[test], y1))\n",
    "    print(\"training finished\")\n",
    "print (\"Cross-Validation AUC Score : %f\" % np.mean(error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics.roc_auc_score(y_train.iloc[test], )\n",
    "# np.transpose(yavg.loc[yavg['index']=='mean',:])[1:]\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain,ytrain,dtest,ytest,test,sub_df, predictors,outcome_var,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=ytrain.values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds,verbose_eval=True,\n",
    "            show_stdv=True)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], ytrain,eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtest[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtest[predictors])[:,1]\n",
    "    \n",
    "    dtrain_predprob1 = alg.predict_proba(test[predictors])[:,1]\n",
    "    sub_df['loan_default']= dtrain_predprob1\n",
    "    sub_df.to_csv('sub1.csv',index=False)    \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(ytest.values, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(ytest, dtrain_predprob))\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.get_booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit_mod(alg, dtrain,ytrain,dtest,ytest,test,sub_df, predictors,outcome_var,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=ytrain.values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds,verbose_eval=True,\n",
    "            show_stdv=True)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], ytrain)\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtest[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtest[predictors])[:,1]\n",
    "    \n",
    "    dtrain_predprob1 = alg.predict_proba(test[predictors])[:,1]\n",
    "#     sub_df['loan_default']= dtrain_predprob1\n",
    "#     sub_df.to_csv('sub1.csv',index=False)    \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(ytest.values, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(ytest, dtrain_predprob))\n",
    "                    \n",
    "#     feat_imp = pd.Series(alg.get_booster().get_fscore()).sort_values(ascending=False)\n",
    "#     feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "#     plt.ylabel('Feature Importance Score')  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "modelfit(XGBClassifier(), X_train,y_train,X_validation,y_validation,test_df,sub_df,predictors,outcome,useTrainCV=True, cv_folds=5, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model6 = RandomForestClassifier(n_estimators = 100, oob_score = True, n_jobs = -1,random_state =50, max_features = \"auto\", min_samples_leaf = 5)\n",
    "\n",
    "modelfit_mod(model6, X_train,y_train,X_validation,y_validation,test_df,sub_df,predictors,outcome,useTrainCV=False, cv_folds=5, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='entropy',max_depth=6)\n",
    "ada = AdaBoostClassifier(base_estimator=tree, n_estimators=29, learning_rate=0.1, random_state=0)\n",
    "\n",
    "modelfit_mod(ada, X_train,y_train,X_validation,y_validation,test_df,sub_df,predictors,outcome,useTrainCV=False, cv_folds=5, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "model9 = VotingClassifier(estimators=[('RF', model6),('Xgb', XGBClassifier()), ('adaboost', ada)], voting='soft')\n",
    "\n",
    "modelfit_mod(model9, X_train,y_train,X_validation,y_validation,test_df,sub_df,predictors,outcome,useTrainCV=False, cv_folds=5, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=500,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=1,\n",
    " objective= 'binary:logistic',\n",
    " nthread=-1,\n",
    " scale_pos_weight=1,\n",
    " seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replce top_20_ft with predictors to run model on all the features\n",
    "modelfit(model1, X_train,y_train,X_validation,y_validation,test_df,sub_df,predictors,outcome,useTrainCV=True, cv_folds=5, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_features = pd.Series(model1.get_booster().get_fscore()).sort_values(ascending=False)[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_ft = list(top_20_features.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#top features only\n",
    "modelfit(model1, X_train,y_train,X_validation,y_validation,test_df,sub_df,top_20_ft,outcome,useTrainCV=True, cv_folds=5, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#top features only\n",
    "modelfit(model1, X_train,y_train,X_validation,y_validation,test_df,sub_df,top_20_ft,outcome,useTrainCV=True, cv_folds=5, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "def Performance(Model,Y,X):\n",
    "    # Perforamnce of the model\n",
    "    fpr, tpr, _ = roc_curve(Y, Model.predict_proba(X)[:,1])\n",
    "    AUC  = auc(fpr, tpr)\n",
    "    print ('the AUC is : %0.4f' %  AUC)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.4f)' % AUC)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Performance(model1,y_validation,X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "np.linspace(0,1,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def acc_model(params):\n",
    "    clf = XGBClassifier(**params)\n",
    "    return cross_val_score(clf, X_train, y_train, scoring='roc_auc',cv=5).mean()\n",
    "\n",
    "param_space = {\n",
    "    'learning_rate': hp.choice('learning_rate', [0.1,0.1]),#np.linspace(0,1,11)),\n",
    "    \n",
    "    'n_estimators': hp.choice('n_estimators', [300,300]),\n",
    "    \n",
    "    'max_depth': hp.choice('max_depth', [3, 5, 7, 9]), #range(1,20)),\n",
    "                               \n",
    "    'min_child_weight': hp.choice('min_child_weight', [1, 3, 5]), #range(1,7)),\n",
    "    \n",
    "    'gamma': hp.choice('gamma', [0,0]),#np.linspace(0,1,11)),\n",
    "    \n",
    "    'subsample': hp.choice('subsample', [0.8,0.8]),#np.linspace(0,1,11)),\n",
    "    \n",
    "    'colsample_bytree': hp.choice('colsample_bytree',[0.8,0.8])# np.linspace(0,1,11)),\n",
    "    \n",
    "#     'max_features': hp.choice('max_features', range(1,55)),\n",
    "    \n",
    "#     'criterion': hp.choice('criterion', [\"gini\", \"entropy\"])\n",
    "#                        \n",
    "     }\n",
    "\n",
    "best = 0\n",
    "def f(params):\n",
    "    global best\n",
    "    acc = acc_model(params)\n",
    "    if acc > best:\n",
    "        best = acc\n",
    "    print ('new best:', best, params)\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(f, param_space, algo=tpe.suggest, max_evals=5, trials=trials)\n",
    "print ('best:')\n",
    "print (best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_test1 = {\n",
    " 'max_depth':[3, 5, 7],\n",
    " 'min_child_weight':[1, 3, 5]\n",
    "}\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=300, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=6, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=6,iid=False, cv=5)\n",
    "gsearch1.fit(X_train,y_train)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "param_test2 = {\n",
    " 'max_depth':[4, 5, 6],\n",
    " 'min_child_weight':[2,3,4]\n",
    "}\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=29, max_depth=6,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=6, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test2, scoring='roc_auc',n_jobs=6,iid=False, cv=5)\n",
    "gsearch1.fit(X_train_std,y)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_\n",
    "\n",
    "param_test2b = {\n",
    " 'min_child_weight':[2,3,4,5,6,7,8]\n",
    "}\n",
    "gsearch2b = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=29, max_depth=6,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=6, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test2b, scoring='roc_auc',n_jobs=6,iid=False, cv=5)\n",
    "gsearch2b.fit(X_train_std,y)\n",
    "gsearch2b.grid_scores_, gsearch2b.best_params_, gsearch2b.best_score_\n",
    "\n",
    "\n",
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=29, max_depth=6,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(X_train_std,y)\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_\n",
    "\n",
    "\n",
    "\n",
    "model2 = XGBClassifier(learning_rate =0.1,\n",
    " n_estimators=29,\n",
    " max_depth=6,\n",
    " min_child_weight=3,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.75,\n",
    " objective= 'binary:logistic',\n",
    " nthread=6,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    " \n",
    "#classification_model(model, df,predictor_var,outcome_var)\n",
    "\n",
    "modelfit(model2, X,y, predictor_var,useTrainCV=True, cv_folds=5, early_stopping_rounds=50)\n",
    "\n",
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=28, max_depth=6,\n",
    " min_child_weight=3, gamma=0, subsample=0.9, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch4.fit(X_train_std,y)\n",
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_\n",
    "\n",
    "\n",
    "param_test5 = {\n",
    " 'subsample':[i/100.0 for i in range(75,90,5)],\n",
    " 'colsample_bytree':[i/100.0 for i in range(75,90,5)]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=28, max_depth=8,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch5.fit(df[predictor_var],df[outcome_var])\n",
    "gsearch5.grid_scores_, gsearch5.best_params_, gsearch5.best_score_\n",
    "\n",
    "\n",
    "param_test6 = {\n",
    " 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=28, max_depth=6,\n",
    " min_child_weight=3, gamma=0, subsample=0.9, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test6, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch6.fit(X_train_std,y)\n",
    "gsearch6.grid_scores_, gsearch6.best_params_, gsearch6.best_score_\n",
    "\n",
    "\n",
    "param_test7 = {\n",
    " 'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05,0.09]\n",
    "}\n",
    "gsearch7 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=28, max_depth=6,\n",
    " min_child_weight=3, gamma=0.1,reg_alpha = 0.01, subsample=0.9, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test7, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch7.fit(X_train_std,y)\n",
    "gsearch7.grid_scores_, gsearch7.best_params_, gsearch7.best_score_\n",
    "\n",
    "\n",
    "xgb4 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=29,\n",
    " max_depth=6,\n",
    " min_child_weight=3,\n",
    " gamma=0.1,\n",
    " subsample=0.9,\n",
    " colsample_bytree=0.8,\n",
    " reg_alpha=0.001,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "\n",
    "modelfit(xgb4, X_train_std,y , predictor_var,useTrainCV=True, cv_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
