{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/home/monster/Downloads/kaggle/AV-L&T-loan/train.csv')\n",
    "test_df = pd.read_csv('/home/monster/Downloads/kaggle/AV-L&T-loan/test.csv')\n",
    "sub_df = pd.read_csv('/home/monster/Downloads/kaggle/AV-L&T-loan/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape,test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['is_train'] = ''\n",
    "test_df['is_train'] = ''\n",
    "data = pd.DataFrame()\n",
    "train_df.loc[:,'is_train'] = 1\n",
    "test_df.loc[:,'is_train'] = 0\n",
    "data = data.append(train_df,sort=False).append(test_df,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treat missing values\n",
    "#86 % values are no so it is safe to impute NO\n",
    "data['Employment.Type'].fillna('Self employed',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.apply(lambda x: sum(x.isnull()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['Employment.Type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['PERFORM_CNS.SCORE.DESCRIPTION'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PERFORM_CNS.SCORE.DESCRIPTION'] = data['PERFORM_CNS.SCORE.DESCRIPTION'].replace(' ', '_', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treat categorical variables\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "d = pd.DataFrame()\n",
    "\n",
    "var_mod = ['Employment.Type','PERFORM_CNS.SCORE.DESCRIPTION']\n",
    "\n",
    "x = pd.get_dummies(data[var_mod])\n",
    "\n",
    "data  = data.drop(var_mod,axis=1)\n",
    "data = pd.concat([data,x], axis=1)\n",
    "    \n",
    "# for i in var_mod:\n",
    "#     print(i)\n",
    "# #     d[str(i)] \n",
    "#     dd = le.fit_transform(data.loc[:,i]).toarray()\n",
    "#     print(dd.shape)\n",
    "# d.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()['PRIMARY.INSTAL.AMT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['disbursed_amount'].hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(data['disbursed_amount']).hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['log_disbursed_amount'] = np.log(data['disbursed_amount'])\n",
    "data['log_asset_cost'] = np.log(data['asset_cost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data['Date.of.Birth'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data['DisbursalDate'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DisbursalDate'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DisbursalDate_month'] = data['DisbursalDate'].map(lambda x : int(x.split('-')[1]))\n",
    "data['DisbursalDate_dayofmonth'] = data['DisbursalDate'].map(lambda x : int(x.split('-')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data['AVERAGE.ACCT.AGE'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data['CREDIT.HISTORY.LENGTH'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data.loc[data['is_train']==1,:]\n",
    "train_df = train_df.drop(['is_train'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = data.loc[data['is_train']==0,:]\n",
    "test_df = test_df.drop(['is_train','loan_default'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.apply(lambda x: sum(x.isnull()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.apply(lambda x: sum(x.isnull()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape,test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictors = ['disbursed_amount', 'asset_cost', 'ltv',\n",
    "       'branch_id', 'supplier_id', 'manufacturer_id', 'Current_pincode_ID',\n",
    "       'State_ID', 'Employee_code_ID',\n",
    "       'MobileNo_Avl_Flag', 'Aadhar_flag', 'PAN_flag', 'VoterID_flag',\n",
    "       'Driving_flag', 'Passport_flag', 'PERFORM_CNS.SCORE', 'PRI.NO.OF.ACCTS',\n",
    "       'PRI.ACTIVE.ACCTS', 'PRI.OVERDUE.ACCTS', 'PRI.CURRENT.BALANCE',\n",
    "       'PRI.SANCTIONED.AMOUNT', 'PRI.DISBURSED.AMOUNT', 'SEC.NO.OF.ACCTS',\n",
    "       'SEC.ACTIVE.ACCTS', 'SEC.OVERDUE.ACCTS', 'SEC.CURRENT.BALANCE',\n",
    "       'SEC.SANCTIONED.AMOUNT', 'SEC.DISBURSED.AMOUNT', 'PRIMARY.INSTAL.AMT',\n",
    "       'SEC.INSTAL.AMT', 'NEW.ACCTS.IN.LAST.SIX.MONTHS',\n",
    "       'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS', 'NO.OF_INQUIRIES',\n",
    "       'Employment.Type_Salaried', 'Employment.Type_Self employed',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_A-Very_Low_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_B-Very_Low_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_C-Very_Low_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_D-Very_Low_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_E-Low_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_F-Low_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_G-Low_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_H-Medium_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_I-Medium_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_J-High_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_K-High_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_L-Very_High_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_M-Very_High_Risk',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_No_Bureau_History_Available',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_Not_Scored:_More_than_50_active_Accounts_found',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_Not_Scored:_No_Activity_seen_on_the_customer_(Inactive)',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_Not_Scored:_No_Updates_available_in_last_36_months',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_Not_Scored:_Not_Enough_Info_available_on_the_customer',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_Not_Scored:_Only_a_Guarantor',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION_Not_Scored:_Sufficient_History_Not_Available','DisbursalDate_month',\n",
    "       'DisbursalDate_dayofmonth']\n",
    "\n",
    "outcome = ['loan_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(train_df[predictors], train_df[outcome], test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,X_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "alg = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import GridSearchCV   #Perforing grid search\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kf = loo.split(X_train_std[predictor_var])\n",
    "kf = KFold(n_splits=5).split(X_train['disbursed_amount'])\n",
    "error = []\n",
    "# yavg = pd.DataFrame()\n",
    "\n",
    "for train, test in kf:\n",
    "    # Filter training data\n",
    "    print(\"training stared\")\n",
    "    train_predictors = X_train[predictors].iloc[train,:]\n",
    "\n",
    "    # The target we're using to train the algorithm.\n",
    "    train_target = y_train.iloc[train].values\n",
    "\n",
    "    # Training the algorithm using the predictors and target.\n",
    "    alg.fit(train_predictors, train_target)\n",
    "    y1 = alg.predict(X_train[predictors].iloc[test,:])\n",
    "#     yavg = yavg.append(pd.Series(y1),ignore_index=True)\n",
    "\n",
    "    #Record error from each cross-validation run\n",
    "    error.append(metrics.roc_auc_score(y_train.iloc[test], y1))\n",
    "    print(\"training finished\")\n",
    "print (\"Cross-Validation AUC Score : %f\" % np.mean(error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics.roc_auc_score(y_train.iloc[test], )\n",
    "# np.transpose(yavg.loc[yavg['index']=='mean',:])[1:]\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain,ytrain,dtest,ytest,test,sub_df, predictors,outcome_var,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=ytrain.values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds,verbose_eval=True,\n",
    "            show_stdv=True)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], ytrain,eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtest[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtest[predictors])[:,1]\n",
    "    \n",
    "    dtrain_predprob1 = alg.predict_proba(test[predictors])[:,1]\n",
    "    sub_df['loan_default']= dtrain_predprob1\n",
    "    sub_df.to_csv('sub1.csv',index=False)    \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(ytest.values, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(ytest, dtrain_predprob))\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.get_booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfit(XGBClassifier(), X_train,y_train,X_validation,y_validation,test_df,sub_df,predictors,outcome,useTrainCV=True, cv_folds=5, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "model2 = SVR(kernel = 'rbf')\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model3 = DecisionTreeRegressor(random_state = 50)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model4 = RandomForestRegressor(n_estimators = 270, max_depth=5,\n",
    "                               min_samples_split=30,min_samples_leaf=12,max_leaf_nodes=30,min_weight_fraction_leaf=0.1,random_state = 50)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "model5 = XGBRegressor()\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model6 = KNeighborsRegressor(n_neighbors =37)\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso ,ElasticNet\n",
    "\n",
    "model7 = Ridge()\n",
    "\n",
    "model8 = Lasso(max_iter=1000,alpha=2000)\n",
    "\n",
    "model9 = RandomForestRegressor()\n",
    "\n",
    "model10 = ElasticNet()\n",
    "\n",
    "from vecstack import stacking\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn(model4,final_train[predictor_var],final_train[outcome_var],\n",
    "         final_test[predictor_var],final_test[outcome_var],predictor_var,\n",
    "         3,'alg2.csv', False, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=1,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfit(model1, X_train,y_train,X_validation,y_validation,test_df,sub_df,predictors,outcome,useTrainCV=True, cv_folds=5, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "def Performance(Model,Y,X):\n",
    "    # Perforamnce of the model\n",
    "    fpr, tpr, _ = roc_curve(Y, Model.predict_proba(X)[:,1])\n",
    "    AUC  = auc(fpr, tpr)\n",
    "    print ('the AUC is : %0.4f' %  AUC)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.4f)' % AUC)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Performance(model1,y_validation,X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0,1,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "def acc_model(params):\n",
    "    clf = XGBClassifier(**params)\n",
    "    return cross_val_score(clf, X_train, y_train).mean()\n",
    "\n",
    "param_space = {\n",
    "    'learning_rate': hp.choice('learning_rate', np.linspace(0,1,11)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', range(1,7)),\n",
    "    'gamma': hp.choice('gamma', np.linspace(0,1,11)),\n",
    "    'subsample': hp.choice('subsample', np.linspace(0,1,11)),\n",
    "    'colsample_bytree': hp.choice('colsample_bytree', np.linspace(0,1,11)),\n",
    "    'max_depth': hp.choice('max_depth', range(1,20)),\n",
    "    'max_features': hp.choice('max_features', range(1,55)),\n",
    "    'n_estimators': hp.choice('n_estimators', range(100,500)),\n",
    "    'criterion': hp.choice('criterion', [\"gini\", \"entropy\"])}\n",
    "\n",
    "best = 0\n",
    "def f(params):\n",
    "    global best\n",
    "    acc = acc_model(params)\n",
    "    if acc > best:\n",
    "        best = acc\n",
    "    print ('new best:', best, params)\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(f, param_space, algo=tpe.suggest, max_evals=5, trials=trials)\n",
    "print ('best:')\n",
    "print (best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=300,\n",
    " max_depth=8,\n",
    " min_child_weight=6,\n",
    " gamma=0.6,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.2,\n",
    " objective= 'binary:logistic',\n",
    " nthread=-1,\n",
    " seed=27)\n",
    "\n",
    "modelfit(model1, X_train,y_train,X_validation,y_validation,test_df,sub_df,predictors,outcome,useTrainCV=True, cv_folds=5, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
